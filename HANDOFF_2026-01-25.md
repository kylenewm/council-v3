# Handoff Document - 2026-01-25

## What Was Accomplished Today

### 1. Testing Enforcement Mechanisms (VERIFIED WORKING)

| Feature | Status | Notes |
|---------|--------|-------|
| **TDD Guard** | ✅ Works | Installed to `~/.council/hooks/python/tdd_guard.py`, added to settings.json |
| **DONE_REPORT detection** | ✅ Code works | Was "dead" only because config wasn't wired |
| **Mode injection** | ✅ Works | All 8 modes fire correctly |

### 2. Auto-Discovery Implementation (COMPLETED)

Added transcript auto-discovery to `council/dispatcher/simple.py`:

```python
def find_transcript_path(worktree: Path) -> Optional[Path]:
    # Converts /Users/foo/project → ~/.claude/projects/-Users-foo-project/
    # Returns most recently modified .jsonl (active session)
```

**Changes made:**
- Added `find_transcript_path()` function (lines ~50-90)
- Integrated into `load_config()` - auto-discovers when worktree exists but transcript_path not specified
- Added periodic refresh in `check_agents()` - refreshes every 60 seconds to handle session changes
- Added `last_transcript_refresh` field to Agent dataclass
- Added `TRANSCRIPT_REFRESH_INTERVAL = 60.0` constant

**NOT YET COMMITTED** - needs commit

### 3. Files Modified

```
council/dispatcher/simple.py  # Auto-discovery + periodic refresh
~/.claude/settings.json       # Added TDD Guard hook
~/.council/hooks/python/tdd_guard.py  # Copied from quality-pack
```

### 4. Files Created

```
TEMP_PLAN_AUDIT.md           # Quick summary audit
FULL_PLAN_AUDIT.md           # Complete plan (268 tasks)
IMPLEMENTATION_QUEUE.md      # Detailed task queue
HANDOFF_2026-01-25.md        # This file
```

---

## What Was Removed From Plan

| Removed | Reason |
|---------|--------|
| **Dispatcher refactor** | Works fine at 1780 lines. Don't fix what isn't broken. |
| **Mode file doc fixes** | Low priority. System works, users use `/inject` not manual file edits. |
| **Most of Phase 1-3** | Overkill. TDD Guard and DONE_REPORT already work. |

---

## What Remains: Blind Tests (NEEDS DESIGN)

### The Core Problem
Single model overfits to its own understanding. Tests written by Claude pass buggy Claude code.

### User's Key Insight: Use Cursor as the Blind Validator

**The approach:**
1. Claude writes code + SPEC.md
2. **Cursor** (with GPT-4 or other model) reads ONLY the SPEC
3. Cursor generates tests based on spec (never sees implementation)
4. Tests come back to Claude Code for execution
5. Failures reveal either: spec ambiguity, implementation bugs, or assumption mismatches

**Why Cursor:**
- Different model (GPT-4, Claude via Cursor, etc.)
- Can execute in isolation
- MCP integrations may exist
- Could also do blind plan review (Cursor critiques Claude's plan)

### Multi-Model Approach
- Could use 2+ models in Cursor (GPT-4 + Claude)
- Each approaches problem differently
- Aggregate findings for more robust validation
- Similar to council pattern we've used before

### Open Questions (Need Research)
1. **MCP integrations** - Is there an MCP server that connects to Cursor?
2. **API approach** - Can we call Cursor API directly?
3. **Local hooks** - Can Cursor watch a folder and auto-execute?
4. **File-based exchange** - Simple: write spec to folder, Cursor picks up, writes tests back?

### Next Session Should Research
- How to programmatically trigger Cursor
- Cursor MCP servers or plugins
- Alternative: Direct GPT-4 API calls (simpler but no Cursor IDE context)
- How Everything-Claude-Code does their blind validation (if at all)

---

## Immediate Next Steps

### 1. Commit Auto-Discovery (5 min)
```bash
git add council/dispatcher/simple.py
git commit -m "Add transcript auto-discovery for DONE_REPORT detection

- find_transcript_path() converts worktree to Claude project folder
- Auto-discovers most recent .jsonl transcript
- Periodic refresh (60s) handles session changes
- No manual config needed - just specify worktree

Co-Authored-By: Claude <noreply@anthropic.com>"
```

### 2. Research Cursor Integration (30-60 min)
- Search for Cursor MCP servers
- Check if Cursor has API
- Look at file-watcher approaches
- Document findings

### 3. Design Blind Test System (60-90 min)
- Spec format (SPEC.md template)
- Exchange mechanism (how specs/tests move between tools)
- Execution flow (who runs what, when)
- Failure classification (spec ambiguity vs bug vs wrong assumption)

---

## Key Files to Read Next Session

| File | Why |
|------|-----|
| `FULL_PLAN_AUDIT.md` | Has the complete audit + what to adopt from Everything-Claude-Code |
| `docs/SYSTEM_AUDIT.md` | Detailed findings on what works vs dead |
| `quality-pack/global/hooks/python/tdd_guard.py` | TDD Guard implementation (works!) |
| `council/dispatcher/simple.py:50-90` | New auto-discovery code |
| `council/dispatcher/simple.py:1270-1285` | Periodic refresh in check_agents |

---

## Summary

**Today's win:** Proved TDD Guard and DONE_REPORT detection WORK. The audit overstated "deadness" - it was just config wiring.

**Tomorrow's focus:** Design blind test system using Cursor as the validator. Research MCP/API/file-exchange approaches.

**Don't do:** Dispatcher refactor, mode doc fixes, or any other yak-shaving. Focus on blind tests.
